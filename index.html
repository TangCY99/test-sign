<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="assets/style.css">
    <title>Sign Language Recognition</title>
</head>
<body>
    <h1>Sign Language Recognition</h1>
    <video id="webcam" autoplay></video>
    <div id="result"></div>
    <script src="dist/models.bundle.js"></script>
    <script src="js/api.js"></script>
    <script>
        let model;
        let webcam;

        async function loadModel() {
            model = await tf.loadGraphModel('model.json'); // Adjust path if necessary
            console.log('Model loaded');
        }

        async function startWebcam() {
            webcam = await navigator.mediaDevices.getUserMedia({ video: true });
            document.getElementById('webcam').srcObject = webcam;

            // Additional logic for processing frames and predicting
            const video = document.getElementById('webcam');
            const resultDiv = document.getElementById('result');

            // Example prediction loop (adjust as needed)
            setInterval(async () => {
                const predictions = await model.executeAsync(tf.browser.fromPixels(video));
                resultDiv.innerHTML = `Prediction: ${predictions}`;
            }, 1000); // Update every second
        }

        window.onload = async () => {
            await loadModel();
            await startWebcam();
        };
    </script>
</body>
</html>
